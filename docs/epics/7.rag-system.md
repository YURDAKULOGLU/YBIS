# Epic 7: RAG System (Document Search & AI Context)

**ID:** 7  
**Status:** Draft  
**Owner:** @ybis-team  
**Created:** 2025-10-29  
**Target:** Closed Beta Launch (Week 6-7)  
**Priority:** P1 (High - AI Quality Critical)

---

## 🎯 1. Epic Goal

RAG (Retrieval Augmented Generation) sistemi oluşturmak:
- ✅ Document upload & chunking
- ✅ pgvector integration (Supabase)
- ✅ OpenAI embeddings (text-embedding-3-small)
- ✅ Semantic search (top-k similarity)
- ✅ AI context injection (query → relevant chunks → LLM)
- ✅ Source citations (AI response shows document sources)
- ✅ Document management UI

**Closed Beta Scope:**
- ✅ pgvector setup (Supabase extension)
- ✅ Document table (documents, chunks with embeddings)
- ✅ Upload flow (file → chunk → embed → store)
- ✅ Query flow (query → embed → similarity search → top-k)
- ✅ Basic document types: PDF, TXT, MD
- ✅ AI context injection (RAG → LLM prompt)
- ❌ Advanced: OCR, image extraction, web scraping (MVP)

---

## 2. Scope (Kapsam)

### **RAG Infrastructure (P0):**
- ✅ Supabase pgvector extension enabled
- ✅ Tables: `documents`, `chunks` (with embedding vector)
- ✅ RAGPort interface definition
- ✅ SupabaseRAGAdapter implementation
- ✅ OpenAI embeddings API integration

### **Document Processing (P0):**
- ✅ File upload (mobile → backend)
- ✅ Text extraction (PDF, TXT, MD)
- ✅ Chunking strategy (500 tokens, 50 overlap)
- ✅ Embedding generation (OpenAI API)
- ✅ Vector storage (pgvector)

### **Semantic Search (P0):**
- ✅ Query embedding (user query → vector)
- ✅ Similarity search (cosine distance)
- ✅ Top-k retrieval (default: 5 chunks)
- ✅ Relevance scoring (distance threshold)

### **AI Context Injection (P0):**
- ✅ RAG query in chat flow
- ✅ Inject relevant chunks into LLM prompt
- ✅ Source citations in AI response
- ✅ Fallback: No relevant docs → general AI response

### **Document Management UI (P1):**
- ✅ Upload screen (select file → upload)
- ✅ Document list (view all uploaded docs)
- ✅ Document detail (view chunks)
- ✅ Delete document (cascade delete chunks)

### **NOT in Scope:**
- ❌ OCR (image text extraction)
- ❌ Web scraping (URL → document)
- ❌ Advanced chunking (semantic, paragraph-based)
- ❌ Multi-modal embeddings (images + text)
- ❌ Document versioning (MVP)

---

## 3. User Stories (6 Stories - 30 Points)

### **Story 7.1: pgvector Setup & RAGPort Architecture (5 points)**
- Enable pgvector extension (Supabase)
- Create `documents` table
- Create `chunks` table (embedding vector(1536))
- RAGPort interface definition
- SupabaseRAGAdapter skeleton

### **Story 7.2: Document Upload & Text Extraction (5 points)**
- Backend endpoint: `/api/rag/upload` (POST)
- File parsing (PDF, TXT, MD)
- Text extraction (use `pdf-parse`, `marked`)
- Store document metadata in `documents` table

### **Story 7.3: Chunking & Embedding Generation (8 points)**
- Chunking logic (500 tokens, 50 overlap)
- OpenAI embeddings API integration
- Batch embedding (up to 100 chunks)
- Store chunks + embeddings in `chunks` table
- Error handling (embedding API failures)

### **Story 7.4: Semantic Search Implementation (5 points)**
- Query embedding (user query → vector)
- pgvector similarity search (`<->` operator)
- Top-k retrieval (configurable, default 5)
- Relevance threshold (distance <0.3)
- Return chunks with metadata (document_id, content, distance)

### **Story 7.5: AI Context Injection & Citations (5 points)**
- RAG query in chat flow
- Inject top-k chunks into LLM prompt
- Prompt engineering: "Based on these documents: [chunks]"
- Extract source citations from response
- Display citations in UI (expandable section)

### **Story 7.6: Document Management UI (2 points)**
- Upload screen (file picker → upload button)
- Document list screen (uploaded docs)
- Document detail (view chunks preview)
- Delete document (confirm dialog)

---

## 4. Success Metrics

**Technical:**
- ✅ Embedding generation latency <5s per document
- ✅ Query latency <2s (embed + search + LLM)
- ✅ Retrieval accuracy >80% (relevant chunks)
- ✅ Zero pgvector errors

**User:**
- ✅ 50%+ users upload at least 1 document
- ✅ RAG query accuracy >75% (user satisfaction)
- ✅ Average 3 documents per user

**AI Quality:**
- ✅ RAG-enabled responses >80% more accurate
- ✅ Source citation rate >90%

---

**Last Updated:** 2025-10-29  
**Story Points:** 30 (~4-5 hafta)
